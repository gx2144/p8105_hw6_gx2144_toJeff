---
title: "homework6"
author: "Guangling Xu"
date: "2019/11/24"
output: github_document
---
---
```{r}
library(tidyverse)
knitr::opts_chunk$set(
    echo = TRUE,
    warning = FALSE,
    fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

### Data Cleaning

```{r}
birthweight =
  read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = factor(babysex, labels = c("male", "female")),
    frace  = factor(frace, labels = c("White","Black","Asian","Puerto Rican","Other")),
    malform = factor(malform, labels = c("absent","present")),
    mrace = factor(mrace, labels = c("White","Black","Asian","Puerto Rican")),
    babysex = fct_infreq(babysex),
    frace = fct_infreq(frace),
    malform=  fct_infreq(malform),
    mrace = fct_infreq(mrace)
     )
```




### Model Building

First we hypothesize that birthweight was affected by all the predcitors given by the dataset.

```{r}
reg_lbt_m = lm(bwt ~ babysex + bhead + blength + delwt + fincome + frace + gaweeks + menarche + momage + mheight + mrace + parity + pnumlbw + pnumsga + ppbmi + ppwt + smoken + wtgain, data = birthweight)  

summary(reg_lbt_m)
```

Then we drop out those whose `p.value` is larger than 0.05 and refit the model.

```{r}
reg_lbt_m_sex = lm(bwt~ babysex + bhead + blength + delwt + gaweeks + parity + smoken, data = birthweight)
broom::tidy(reg_lbt_m_sex) %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable()
```

The table shows that all the predictors now cnotribute to the fitted model due to small `p.value`.

There for the model we set on the factors underying birthweight is 
`birthweight ~ babysex + bhead + blength + delwt + gaweeks + parity + smoken`.


### Diagnositic

Then we diagonise whether the linear model fit.

```{r}
resplot_mrace= birthweight %>% 
  modelr::add_residuals(reg_lbt_m_sex) %>% 
  modelr::add_predictions(reg_lbt_m_sex) %>%
  ggplot(aes(x = pred, y = resid)) + geom_point()+
  geom_line( y = 0, color = "red")+
  labs(
    title = "Model Residuals against Fitted Values",
    x = "Fitted values",
    y = "Residuals"
  )
resplot_mrace

```

From the plot above,we can see that most of the fitted values lie between 2000-4000 and most of the residuals are randomly lie around zero, indicating linearity . 


### Comparing models

```{r}
reg_model1 = lm(bwt~ babysex + bhead + blength + delwt + gaweeks + parity + smoken, data = birthweight)
reg_model2 = lm(bwt ~ blength + gaweeks, data = birthweight)
reg_model3 = lm(bwt~ bhead*blength + bhead *babysex + blength*babysex + bhead*babysex*blength,  data = birthweight)
```


```{r}
reg_model2 %>%  
  broom::tidy() %>%  
  select(term, estimate, p.value)%>% 
  knitr::kable()
```

This table shows that blength and gaweeks all have extremly small `p.value`, indicating the conefficient of these two are both away from zero.

```{r}
reg_model3 %>%
  broom::tidy() %>%
  select(term, estimate, p.value)%>%  
  knitr::kable()
```

This table shows that except for the interaction between `bhead` and `blength`, all other covariates have coefficients far away from zero. 

```{r}
cv_df =
  modelr::crossv_mc(birthweight, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(reg_model1  = map(train, ~lm(bwt~ mrace + babysex, data = .x)),
         reg_model2   = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         reg_model3  = map(train, ~lm(bwt~ bhead+ blength + babysex + bhead*blength + bhead *babysex + blength*babysex + bhead*babysex*blength, data = as_tibble(.x)))) %>% 
  mutate(rmse_model1 = map2_dbl(reg_model1 , test, ~modelr::rmse(model = .x, data = .y)),
         rmse_model2  = map2_dbl(reg_model2, test, ~modelr::rmse(model = .x, data = .y)),
         rmse_model3 = map2_dbl(reg_model3, test, ~modelr::rmse(model = .x, data = .y)))

```


```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin(aes(fill = model))+
  labs(
    title = "Root Mean Square Error Comparison",
    x = "Models",
    y = "Root Mean Square Error"
  )
```
Based on the plot above, it is clear that the third model with the lowest RMSE ,which is the one using head circumference, length, sex, and all interactions (including the three-way interaction) between these fits the best. 


## Problem 2

```{r,message=FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

set.seed(1)
```

### Drawing many bootstrap samples

```{r}
reg_weather = lm(tmax ~ tmin,data = weather_df)
```

```{r}
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

boot_straps = 
  data_frame(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df ))
  )

```


### Distribution of estimate quantities

```{r}
bootstrap_results = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap_sample, -models) %>% 
  unnest() 


bootstrap_results_log = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>%
  select(-strap_sample, -models) %>% 
  unnest() %>% 
  select(strap_number,term, estimate)

bootstrap_results_log = bootstrap_results_log %>% 
  mutate(
    term = factor(term,labels = c("beta0","beta1"))
  ) %>% 
  pivot_wider(
    names_from = "term",
    values_from = "estimate"
  ) %>% 
  mutate(
    log_beta0_beta1 = log(beta0*beta1)
  )


estimate_r = data.frame(
  quantity = "adj_r_squared",
  estimate_mean = mean(pull(bootstrap_results, adj.r.squared)), 
  estimate_sd = sd(pull(bootstrap_results, adj.r.squared))
)



estimate_log = data.frame(
  quantity = "log_beta0_1",
  estimate_mean = mean(pull(bootstrap_results_log, log_beta0_beta1)), 
  estimate_sd = sd(pull(bootstrap_results_log,log_beta0_beta1))
)


bind_rows(estimate_r, estimate_log) %>% 
  knitr::kable()

```